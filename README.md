## A collection of (no great) example of java code to understand Apache Spark Data structures


Spark allows programmers to develop complex, multi-step data pipelines using directed acyclic graph (DAG) pattern. It  supports in-memory data sharing across DAGs, so that different jobs can work with the same data.
Spark (can) runs on top of existing Hadoop Distributed File System (HDFS) infrastructure to provide enhanced and additional functionality. 

This example are designed to run locally, but if you remove in any main class the "local[]" option and provide the right way to read input you can use its on clusters.

## You can use a simple docker compose container to simply try this code in cluster mode

Follow this link to find a simple docker container that build a cluster with 1 master node and 2 worker.


[a link](https://github.com/gaetanofabiano/dockerSparkCluster)

## Install

check out the project and run

mvc clean install

# Apache Spark Version

2.4.1

# Credits

She knows

